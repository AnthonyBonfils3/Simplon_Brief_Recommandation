{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "shaped-mattress",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "perceived-throw",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    totalUsers  totalPlays     avgPlays\n",
      "name                                                   \n",
      "Britney Spears             522     2393140  4584.559387\n",
      "Depeche Mode               282     1301308  4614.567376\n",
      "Lady Gaga                  611     1291387  2113.563011\n",
      "Christina Aguilera         407     1058405  2600.503686\n",
      "Paramore                   399      963449  2414.659148\n",
      "...                        ...         ...          ...\n",
      "Morris                       1           1     1.000000\n",
      "Eddie Kendricks              1           1     1.000000\n",
      "Excess Pressure              1           1     1.000000\n",
      "My Mine                      1           1     1.000000\n",
      "A.M. Architect               1           1     1.000000\n",
      "\n",
      "[17632 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "plays = pd.read_csv('Datas/lastfm/user_artists.dat', sep='\\t') ## Dataset of relation between an artist \n",
    "## an user and the number listening \n",
    "artists = pd.read_csv('Datas/lastfm/artists.dat', sep='\\t', usecols=['id','name']) ## id\tname\turl\tpictureURL\n",
    "\n",
    "# Merge artist and user pref data\n",
    "ap = pd.merge(artists, plays, how=\"inner\", left_on=\"id\", right_on=\"artistID\")\n",
    "ap = ap.rename(columns={\"weight\": \"playCount\"})\n",
    "#print(ap)\n",
    "# Group artist by name\n",
    "artist_rank = ap.groupby(['name']) \\\n",
    "    .agg({'userID' : 'count', 'playCount' : 'sum'}) \\\n",
    "    .rename(columns={\"userID\" : 'totalUsers', \"playCount\" : \"totalPlays\"}) \\\n",
    "    .sort_values(['totalPlays'], ascending=False)\n",
    "\n",
    "artist_rank['avgPlays'] = artist_rank['totalPlays'] / artist_rank['totalUsers']\n",
    "print(artist_rank)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "concrete-dryer",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "density: 0.28 %\n"
     ]
    }
   ],
   "source": [
    "# Merge into ap matrix\n",
    "\n",
    "ap = ap.join(artist_rank, on=\"name\", how=\"inner\") \\\n",
    "    .sort_values(['playCount'], ascending=False)\n",
    "#print(ap)\n",
    "\n",
    "# Preprocessing\n",
    "pc = ap.playCount\n",
    "play_count_scaled = (pc - pc.min()) / (pc.max() - pc.min())\n",
    "ap = ap.assign(playCountScaled=play_count_scaled)\n",
    "#print(ap)\n",
    "\n",
    "# Build a user-artist rating matrix \n",
    "ratings_df = ap.pivot(index='userID', columns='artistID', values='playCountScaled')\n",
    "ratings = ratings_df.fillna(0).values\n",
    "#print(ratings)\n",
    "\n",
    "# Show sparsity\n",
    "sparsity = float(len(ratings.nonzero()[0])) / (ratings.shape[0] * ratings.shape[1]) * 100\n",
    "print(\"density: %.2f %%\" % sparsity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "metric-nursery",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rating matrix shape (1892, 17632)\n"
     ]
    }
   ],
   "source": [
    "from scipy.sparse import csr_matrix, csc_matrix, coo_matrix\n",
    "'''selon le type de matrice sparse, la compresion n est pas la même'''\n",
    "\n",
    "# Build a sparse matrix\n",
    "X = csr_matrix(ratings)\n",
    "#print(X)\n",
    "\n",
    "n_users, n_items = ratings_df.shape\n",
    "print(\"rating matrix shape\", ratings_df.shape)\n",
    "\n",
    "user_ids = ratings_df.index.values\n",
    "artist_names = ap.sort_values(\"artistID\")[\"name\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "synthetic-height",
   "metadata": {},
   "outputs": [],
   "source": [
    "from lightfm import LightFM\n",
    "from lightfm.evaluation import auc_score, precision_at_k, recall_at_k\n",
    "from lightfm.cross_validation import random_train_test_split\n",
    "from lightfm.data import Dataset\n",
    "\n",
    "# Build data references + train test\n",
    "Xcoo = X.tocoo()\n",
    "# initialise le dataset du type (triplet)\n",
    "data = Dataset()\n",
    "data.fit(np.arange(n_users), np.arange(n_items))\n",
    "interactions, weights = data.build_interactions(zip(Xcoo.row, Xcoo.col, Xcoo.data)) \n",
    "train, test = random_train_test_split(interactions)\n",
    "\n",
    "# Ignore that (weight seems to be ignored...)\n",
    "#train = train_.tocsr()\n",
    "#test = test_.tocsr()\n",
    "#train[train==1] = X[train==1]\n",
    "#test[test==1] = X[test==1]\n",
    "\n",
    "# To be completed..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cordless-college",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<lightfm.lightfm.LightFM at 0x7f5c471bb8b0>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train\n",
    "model = LightFM(learning_rate=0.05, loss='warp')\n",
    "model.fit(train, epochs=10, num_threads=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "suffering-carry",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: train 0.37, test 0.13.\n",
      "AUC: train 0.96, test 0.86.\n"
     ]
    }
   ],
   "source": [
    "# Evaluate\n",
    "train_precision = precision_at_k(model, train, k=10).mean()\n",
    "test_precision = precision_at_k(model, test, k=10, train_interactions=train).mean()\n",
    "\n",
    "train_auc = auc_score(model, train).mean()\n",
    "test_auc = auc_score(model, test, train_interactions=train).mean()\n",
    "\n",
    "print('Precision: train %.2f, test %.2f.' % (train_precision, test_precision))\n",
    "print('AUC: train %.2f, test %.2f.' % (train_auc, test_auc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "amazing-saturn",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Depeche Mode' 'The Killers' 'Coldplay' ... 'HAKUEI' 'Nano' 'Hi:BRiD']\n"
     ]
    }
   ],
   "source": [
    "# Predict\n",
    "scores = model.predict(0, np.arange(n_items))\n",
    "top_items = artist_names[np.argsort(-scores)]\n",
    "print(top_items)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "stock-equation",
   "metadata": {},
   "source": [
    "## Choix de la meilleur fonction de coût"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "refined-weekend",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from collections import defaultdict\n",
    "\n",
    "loss_val = ['logistic', 'bpr', 'warp', 'warp-kos']\n",
    "\n",
    "def append_res_list(res, name, time, prec, recall, AUC):\n",
    "    res[name].append([\n",
    "                time,\n",
    "                prec,  \n",
    "                recall,           \n",
    "                AUC,           \n",
    "            ])\n",
    "    return res\n",
    "\n",
    "train_res = defaultdict(list)\n",
    "test_res = defaultdict(list)\n",
    "for loss in loss_val:\n",
    "    name = 'loss-'+loss\n",
    "    \n",
    "    model = LightFM(learning_rate=0.05, loss=loss)\n",
    "    t0 = time.time()\n",
    "    model.fit(train, epochs=10, num_threads=2)\n",
    "    fit_time = time.time() - t0\n",
    "    \n",
    "    ## precision\n",
    "    train_precision = precision_at_k(model, train, k=10).mean()\n",
    "    test_precision = precision_at_k(model, test, k=10, train_interactions=train).mean()\n",
    "    \n",
    "    ## recal\n",
    "    train_recall = recall_at_k(model, train, k=10).mean()\n",
    "    test_recall = recall_at_k(model, test, k=10, train_interactions=train).mean()\n",
    "    \n",
    "    ## AUC\n",
    "    train_auc = auc_score(model, train).mean()\n",
    "    test_auc = auc_score(model, test, train_interactions=train).mean()\n",
    "    \n",
    "    ## resultats summury\n",
    "    \n",
    "    train_res = append_res_list(train_res, name, fit_time, \n",
    "                         train_precision, train_recall, train_auc)\n",
    "    \n",
    "\n",
    "    test_res = append_res_list(test_res, name, fit_time, \n",
    "                         test_precision, test_recall, test_auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "systematic-addiction",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_df_resultats(res):\n",
    "    # Compute mean and std\n",
    "    final = {}\n",
    "    for model in res:\n",
    "        arr = np.array(res[model])\n",
    "        final[model] = {\n",
    "            \"time (s)\" : arr[:,0].mean().round(3),\n",
    "            \"precision \": arr[:,1].mean().round(3),\n",
    "            \"recall\": arr[:,2].mean().round(3),\n",
    "            \"AUC\": arr[:,3].mean().round(3),\n",
    "        }\n",
    "\n",
    "    df = pd.DataFrame.from_dict(final, orient=\"index\").round(3)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "theoretical-facility",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time (s)</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>AUC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>loss-logistic</th>\n",
       "      <td>0.405</td>\n",
       "      <td>0.196</td>\n",
       "      <td>0.051</td>\n",
       "      <td>0.888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>loss-bpr</th>\n",
       "      <td>0.509</td>\n",
       "      <td>0.369</td>\n",
       "      <td>0.095</td>\n",
       "      <td>0.855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>loss-warp</th>\n",
       "      <td>0.557</td>\n",
       "      <td>0.375</td>\n",
       "      <td>0.097</td>\n",
       "      <td>0.964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>loss-warp-kos</th>\n",
       "      <td>1.156</td>\n",
       "      <td>0.326</td>\n",
       "      <td>0.084</td>\n",
       "      <td>0.887</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               time (s)  precision   recall    AUC\n",
       "loss-logistic     0.405       0.196   0.051  0.888\n",
       "loss-bpr          0.509       0.369   0.095  0.855\n",
       "loss-warp         0.557       0.375   0.097  0.964\n",
       "loss-warp-kos     1.156       0.326   0.084  0.887"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train = print_df_resultats(train_res)\n",
    "df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "inside-glossary",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time (s)</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>AUC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>loss-logistic</th>\n",
       "      <td>0.405</td>\n",
       "      <td>0.065</td>\n",
       "      <td>0.067</td>\n",
       "      <td>0.807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>loss-bpr</th>\n",
       "      <td>0.509</td>\n",
       "      <td>0.124</td>\n",
       "      <td>0.128</td>\n",
       "      <td>0.780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>loss-warp</th>\n",
       "      <td>0.557</td>\n",
       "      <td>0.130</td>\n",
       "      <td>0.133</td>\n",
       "      <td>0.854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>loss-warp-kos</th>\n",
       "      <td>1.156</td>\n",
       "      <td>0.115</td>\n",
       "      <td>0.118</td>\n",
       "      <td>0.815</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               time (s)  precision   recall    AUC\n",
       "loss-logistic     0.405       0.065   0.067  0.807\n",
       "loss-bpr          0.509       0.124   0.128  0.780\n",
       "loss-warp         0.557       0.130   0.133  0.854\n",
       "loss-warp-kos     1.156       0.115   0.118  0.815"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test = print_df_resultats(test_res)\n",
    "df_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "lined-washington",
   "metadata": {},
   "source": [
    "Le meilleur modèle terme de précision, recall et AUC est lorsque l'on choisi la fonction loss = 'wrap'. C'est vrai pour le training et le testing set."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "spare-alabama",
   "metadata": {},
   "source": [
    "## Test d'optimisation d'hyper-paramètres avec GreadSearchCV\n",
    "\n",
    "Je ne suis pas sûre que ce soit compatible avec les modèles lightfm mais le jeu en vaut la chandèle pour pouvoir optimiser tous les paramètre avec une grille de recherche."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "linear-proposal",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['loss', 'learning_schedule', 'no_components', 'learning_rate', 'k', 'n', 'rho', 'epsilon', 'max_sampled', 'item_alpha', 'user_alpha', 'random_state'])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## affichage des paramètre \n",
    "LightFM().get_params().keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "handy-child",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.metrics import make_scorer\n",
    "\n",
    "AUC_scorer = make_scorer(auc_score)\n",
    "\n",
    "grid_params = {\n",
    "    'loss' : ['logistic', 'bpr', 'warp', 'warp-kos'],\n",
    "    'no_components' : [1, 2, 5, 10, 20],\n",
    "    'learning_rate' : [0.1, 5e-2, 1e-2, 1e-3],\n",
    "    'k' : [1, 2, 5, 10, 20],\n",
    "} \n",
    "\n",
    "gs = GridSearchCV(LightFM(),\n",
    "                  grid_params,\n",
    "                  cv = 5,\n",
    "                  scoring=AUC_scorer,\n",
    "                  n_jobs = -1\n",
    "                 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "revised-video",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "_score() missing 1 required positional argument: 'y_true'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31m_RemoteTraceback\u001b[0m                          Traceback (most recent call last)",
      "\u001b[0;31m_RemoteTraceback\u001b[0m: \n\"\"\"\nTraceback (most recent call last):\n  File \"/home/anthony/anaconda3/lib/python3.8/site-packages/joblib/externals/loky/process_executor.py\", line 431, in _process_worker\n    r = call_item()\n  File \"/home/anthony/anaconda3/lib/python3.8/site-packages/joblib/externals/loky/process_executor.py\", line 285, in __call__\n    return self.fn(*self.args, **self.kwargs)\n  File \"/home/anthony/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 595, in __call__\n    return self.func(*args, **kwargs)\n  File \"/home/anthony/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n    return [func(*args, **kwargs)\n  File \"/home/anthony/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n    return [func(*args, **kwargs)\n  File \"/home/anthony/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 560, in _fit_and_score\n    test_scores = _score(estimator, X_test, y_test, scorer)\n  File \"/home/anthony/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 605, in _score\n    scores = scorer(estimator, X_test)\n  File \"/home/anthony/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_scorer.py\", line 87, in __call__\n    score = scorer._score(cached_call, estimator,\nTypeError: _score() missing 1 required positional argument: 'y_true'\n\"\"\"",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-de4c6920bf83>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mgs_res\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     70\u001b[0m                           FutureWarning)\n\u001b[1;32m     71\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    734\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    735\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 736\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    738\u001b[0m         \u001b[0;31m# For multi-metric evaluation, store the best_index_, best_params_ and\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1186\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1187\u001b[0m         \u001b[0;34m\"\"\"Search all candidates in param_grid\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1188\u001b[0;31m         \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mParameterGrid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1189\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[0;34m(candidate_params)\u001b[0m\n\u001b[1;32m    706\u001b[0m                               n_splits, n_candidates, n_candidates * n_splits))\n\u001b[1;32m    707\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 708\u001b[0;31m                 out = parallel(delayed(_fit_and_score)(clone(base_estimator),\n\u001b[0m\u001b[1;32m    709\u001b[0m                                                        \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    710\u001b[0m                                                        \u001b[0mtrain\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1052\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieval_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1054\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1055\u001b[0m             \u001b[0;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1056\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    931\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    932\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'supports_timeout'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 933\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    934\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    935\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mwrap_future_result\u001b[0;34m(future, timeout)\u001b[0m\n\u001b[1;32m    540\u001b[0m         AsyncResults.get from multiprocessing.\"\"\"\n\u001b[1;32m    541\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 542\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfuture\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    543\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mCfTimeoutError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    544\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/concurrent/futures/_base.py\u001b[0m in \u001b[0;36mresult\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    437\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mCancelledError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    438\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_state\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mFINISHED\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 439\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__get_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    440\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    441\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/concurrent/futures/_base.py\u001b[0m in \u001b[0;36m__get_result\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    386\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__get_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    387\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_exception\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 388\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_exception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    389\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    390\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: _score() missing 1 required positional argument: 'y_true'"
     ]
    }
   ],
   "source": [
    "gs_res = gs.fit(train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "southern-rouge",
   "metadata": {},
   "source": [
    "## Fonction de recommandation\n",
    "On va entreiner le modèle avec fonction loss = 'warp'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "thrown-jaguar",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<lightfm.lightfm.LightFM at 0x7f5c471bb520>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = LightFM(learning_rate=0.05, loss='warp')\n",
    "model.fit(train, epochs=10, num_threads=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "lyric-serial",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Liste des 5 artistes recommandés : ['Bonobo' 'Apparat' 'Amethystium' 'Autechre' 'Solar Fields' 'Ochre'\n",
      " 'Boards of Canada' 'múm' 'Four Tet' 'Pleq']\n"
     ]
    }
   ],
   "source": [
    "def get_recommandation(user, model=model):\n",
    "    scores = model.predict(user, np.arange(n_items))\n",
    "    top_items = artist_names[np.argsort(-scores)]\n",
    "    print('Liste des 5 artistes recommandés :', top_items[:10])\n",
    "    return top_items\n",
    "\n",
    "user = 1\n",
    "top_items = get_recommandation(user)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
